{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33be6d8f-a081-40fe-beb2-ec9814a54a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from msr.training.data.datamodules import PtbXLDataModule\n",
    "from msr.training.trainers import MLClassifierTrainer, MLRegressorTrainer\n",
    "from msr.data.download.ptbxl import FS\n",
    "from msr.evaluation.plotters import MatplotlibPlotter, PlotlyPlotter, plot_classifier_evaluation, BasePlotter\n",
    "from msr.evaluation.loggers import MLWandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843a818c-56f6-400f-a6f5-67eb259904c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_type = \"whole_signal_features\"\n",
    "TARGET = \"diagnostic_class\"\n",
    "BASE_PARAMS = dict(fs=FS, target=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ad6977-a562-4100-84bc-0f3c9d1e19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Literal, Tuple\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from msr.evaluation.metrics import get_classification_metrics\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from abc import abstractmethod\n",
    "from functools import partial\n",
    "\n",
    "loss_functions = {\n",
    "    \"mae\": nn.L1Loss(), \n",
    "    \"mse\": nn.MSELoss(), \n",
    "    \"negative_log_likelihood\": nn.NLLLoss(), \n",
    "    \"cross_entropy\": nn.CrossEntropyLoss(),\n",
    "    \"hinge_embedding\": nn.HingeEmbeddingLoss()\n",
    "}\n",
    "    \n",
    "        \n",
    "class BaseTask:\n",
    "    @abstractmethod\n",
    "    def get_metrics(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def plot_evaluation(\n",
    "        self, \n",
    "        y_values: Dict[str, Tuple[np.ndarray, np.ndarray]], \n",
    "        metrics: Dict[str, float], \n",
    "        plotter: BasePlotter,\n",
    "        feature_importances: List[float] = None\n",
    "    ):\n",
    "        pass\n",
    "   \n",
    "\n",
    "class Classifier:\n",
    "    def get_metrics(self, preds, target):\n",
    "        return get_classification_metrics(num_clases=self.datamodule.num_classes, preds=preds, target=target)\n",
    "    \n",
    "    def plot_evaluation(\n",
    "        self, \n",
    "        y_values: Dict[str, Tuple[np.ndarray, np.ndarray]], \n",
    "        metrics: Dict[str, float], \n",
    "        plotter: BasePlotter,\n",
    "        feature_importances: List[float] = None\n",
    "    ):\n",
    "        return plot_classifier_evaluation(\n",
    "            y_values=y_values,\n",
    "            metrics=metrics,\n",
    "            class_names=self.datamodule.class_names,\n",
    "            feature_names=self.feature_names,\n",
    "            feature_importances=feature_importances,\n",
    "            plotter=plotter\n",
    "        )\n",
    "    \n",
    "    \n",
    "class Regressor:  \n",
    "    def get_metrics(self, preds, target):\n",
    "        return get_regression_metrics(preds=preds, target=target)\n",
    "        \n",
    "    def plot_evaluation(\n",
    "        self, \n",
    "        y_values: Dict[str, Tuple[np.ndarray, np.ndarray]], \n",
    "        metrics: Dict[str, float], \n",
    "        plotter: BasePlotter,\n",
    "        feature_importances: List[float] = None\n",
    "    ):\n",
    "        return plot_regressor_evaluation(\n",
    "            y_values=y_values,\n",
    "            metrics=metrics,\n",
    "            feature_names=self.feature_names,\n",
    "            feature_importances=feature_importances,\n",
    "            plotter=plotter\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class BaseTrainer:\n",
    "    def __init__(self, model, datamodule):\n",
    "        self.model = model\n",
    "        self.datamodule = datamodule\n",
    "        self.feature_names = datamodule.feature_names\n",
    "   \n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, data):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluate(self, plotter: BasePlotter = None, logger: MLWandbLogger = None):\n",
    "        all_y_values = {\n",
    "            # \"train\": {\"preds\": self.train(), \"target\": self.datamodule.train.targets},\n",
    "            \"val\": {\n",
    "                \"preds\": self.predict(self.datamodule.val.data), \n",
    "                \"target\": self.datamodule.val.targets\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"preds\": self.predict(self.datamodule.test.data), \n",
    "                \"target\": self.datamodule.test.targets\n",
    "            },\n",
    "        }\n",
    "\n",
    "        metrics = {split: self.get_metrics(**y_values) for split, y_values in all_y_values.items()}\n",
    "        evaluation_results = {\n",
    "            \"metrics\": pd.json_normalize(metrics, sep=\"/\").to_dict(orient=\"records\")[0]  # flattened dict\n",
    "        }\n",
    "        if plotter is not None:\n",
    "            evaluation_results[\"figs\"] = self.plot_evaluation(all_y_values, metrics, plotter)\n",
    "        if logger is not None:\n",
    "            for name, results in evaluation_results.items():\n",
    "                blacklist = [\"/roc\"]\n",
    "                filtered_results = {\n",
    "                    name: value for name, value in results.items() if all([key not in name for key in blacklist])\n",
    "                }\n",
    "                logger.log(filtered_results)\n",
    "            logger.finish()\n",
    "        return evaluation_results    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class DLTrainer(BaseTrainer):\n",
    "    def __init__(self, trainer: pl.Trainer, model: nn.Module, datamodule: pl.LightningDataModule):\n",
    "        self.trainer = trainer\n",
    "        super().__init__(model, datamodule)\n",
    "\n",
    "    def fit(self):\n",
    "        self.trainer.fit(self.model, self.datamodule)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model(data) \n",
    "    \n",
    "    \n",
    "class DLClassifierTrainer(DLTrainer, Classifier):\n",
    "    def __init__(self, trainer: pl.Trainer, model: nn.Module, datamodule: pl.LightningDataModule):\n",
    "        super().__init__(trainer, model, datamodule)\n",
    "        \n",
    "        \n",
    "class DLRegressorTrainer(DLTrainer, Regressor):\n",
    "    def __init__(self, trainer: pl.Trainer, model: nn.Module, datamodule: pl.LightningDataModule):\n",
    "        super().__init__(trainer, model, datamodule)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class MLTrainer(BaseTrainer):\n",
    "    def fit(self):\n",
    "        self.model.fit(X=self.datamodule.train.data.numpy(), y=self.datamodule.train.targets)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "\n",
    "class MLClassifierTrainer(MLTrainer, Classifier):\n",
    "    def __init__(self, model, datamodule: pl.LightningDataModule):\n",
    "        super().__init__(model, datamodule)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "\n",
    "class MLRegressorTrainer(MLTrainer, Regressor):\n",
    "    def __init__(self, model: nn.Module, datamodule: pl.LightningDataModule):\n",
    "        super().__init__(model, datamodule)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "094479c1-c7b0-4a33-96c6-9c1b52b8d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: nn.Module,\n",
    "        loss_metric: Literal[\"mse\", \"mae\"] = \"mse\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.save_hyperparameters(logger=False, ignore=['net'])\n",
    "        self.criterion = loss_functions[loss_metric]\n",
    "        self.get_metrics = partial(get_classification_metrics, num_clases=self.net.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx: int, stage: str):\n",
    "        data, target = batch\n",
    "        preds = self.forward(data)\n",
    "        loss = self.criterion(preds, target)\n",
    "        return {\"loss\": loss, \"preds\": preds, \"target\": target}\n",
    "        \n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        return self._common_step(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx: int):\n",
    "        return self._common_step(batch, batch_idx, \"val\")\n",
    "        \n",
    "    def test_step(self, batch, batch_idx: int):\n",
    "        return self._common_step(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _common_epoch_end(self, outputs, stage: str):\n",
    "        loss = torch.tensor([output[\"loss\"] for output in outputs]).mean()\n",
    "        preds = torch.cat([output[\"preds\"] for output in outputs], dim=0)\n",
    "        target = torch.cat([output[\"target\"] for output in outputs], dim=0)\n",
    "        metrics = self.metrics.get_metrics(preds, target)\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics = {f\"{stage}/{name}\": value for name, value in metrics.items()}\n",
    "        results = {\n",
    "            \"metrics\": metrics,\n",
    "            \"y_values\": {\"preds\": preds, \"target\": target}\n",
    "        }\n",
    "        if self.trainer.sanity_checking or self.trainer.testing:\n",
    "            return results\n",
    "        self.log(f\"{stage}/loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=False)\n",
    "        self.logger.log_metrics(metrics, step=self.current_epoch)\n",
    "        return results\n",
    "\n",
    "    def training_epoch_end(self, outputs: List):\n",
    "        results = self._common_epoch_end(outputs, \"train\")\n",
    "        trainer_metrics = {\n",
    "            \"epoch\": self.current_epoch,\n",
    "            \"learning_rate\": self.optimizers().param_groups[0][\"lr\"],\n",
    "        }\n",
    "        self.logger.log_metrics(trainer_metrics, step=self.current_epoch)\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs: List):\n",
    "        results = self._common_epoch_end(outputs, \"val\")\n",
    "        \n",
    "\n",
    "    def test_epoch_end(self, outputs: Dict):\n",
    "        results = self._common_epoch_end(outputs, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params=self.parameters(),\n",
    "            lr=0.001,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=0.01,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.1, \n",
    "            patience=10, \n",
    "            threshold=0.0001,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler, \n",
    "                \"monitor\": \"val/loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3b9622-0570-4678-ac90-0d687194669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim=1000, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3356e75-607a-4eca-bd08-945ff22c40af",
   "metadata": {},
   "source": [
    "---\n",
    "# **ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4a97cf-eda6-4791-980c-66a1cba22a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "datamodule = PtbXLDataModule(rep_type, **BASE_PARAMS)\n",
    "datamodule.setup()\n",
    "\n",
    "ptbxl_ml_trainer = MLClassifierTrainer(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1517e9-3511-482f-a39d-28123b40f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_ml_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d25435-4868-4b68-bc08-8dae4c2ce8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bc1d3-7816-4015-9e88-00ae6248c1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a027a54-9754-465d-b235-5765a145c742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b8455-dd10-4980-b9f3-86672f7f9b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d7027-bc3a-42a8-94d9-a70df9cdc19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022eeacf-8089-4890-871f-ee7c53b56c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb514d-a75f-4cad-9b37-3853c9c07525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35357678-0250-4a64-81e8-288d12955a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPClassifier(\n",
    "    in_dim=dm.feature_names.__len__(),\n",
    "    num_classes=dm.class_names.__len__()\n",
    ")\n",
    "\n",
    "model = ClassifierModule(net, \"negative_log_likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3394548d-b09c-4f27-a14e-45fd864343fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shate/.cache/pypoetry/virtualenvs/msr-xbuxOujG-py3.8/lib/python3.8/site-packages/pytorch_lightning/loggers/wandb.py:387: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(project='ptbxl', name='DL')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb378687-f17c-4a7f-9437-e462f7be0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_trainer = DLClassifierTrainer(trainer, model, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
