{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbefd871-67e4-4c56-b276-371e8d966bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys         \n",
    "sys.path.append('./../../src/') \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from data.ptbxl import PTBXLDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c787a172-a01f-4dcb-8b7e-bee29e66cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_datamodule = PTBXLDataModule(\n",
    "    representation_type = 'per_beat_features',\n",
    "    fs = 100,\n",
    "    target = 'diagnostic_class',\n",
    "    batch_size = 64,\n",
    "    num_workers = 8\n",
    ")\n",
    "ptbxl_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1bdf68-d72d-404b-9cb5-f12a2f6e828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim=1000, n_classes=5):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # nn.Linear(in_dim, in_dim // 2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_dim // 2, in_dim // 4),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(in_dim, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        if torch.any(probs.isnan()) or torch.any(probs.isinf()):\n",
    "            print(out)\n",
    "        return probs\n",
    "    \n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_layers, bidirectional, n_classes=5):\n",
    "        super().__init__()\n",
    "        output_layers = 2 if bidirectional else 1\n",
    "        self.net = nn.ModuleDict({\n",
    "            'lstm': nn.LSTM(\n",
    "                input_size=in_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                bidirectional=bidirectional\n",
    "            ),\n",
    "            'dropout': nn.Dropout(p=0.5),\n",
    "            'linear': nn.Linear(output_layers * hidden_dim, n_classes),\n",
    "        })\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, n_channels, n_beats, n_feats = x.shape\n",
    "        x = x.view(batch_size, n_beats, n_channels * n_feats)\n",
    "        out, _ = self.net['lstm'](x)\n",
    "        out = out[:, -1, :]\n",
    "        # print(f'lstm output={out.size()}')\n",
    "\n",
    "        # From [seq len, batch, num_directions * hidden_size]\n",
    "        # to [batches, seqs, seq_len,prediction]\n",
    "        # out = out.view(x_batches, x_seqs, x_seq_len, -1)\n",
    "        # print(f'transformed output={out.size()}')\n",
    "\n",
    "        # Data is fed to the Linear layer\n",
    "        out = self.net['linear'](out)\n",
    "        # print(f'linear output={out.size()}')\n",
    "\n",
    "        # The prediction utilizing the whole sequence is the last one\n",
    "        # y_pred = out[:, :, -1].unsqueeze(-1)\n",
    "        # print(f'y_pred={y_pred.size()}')\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720b7cdf-926e-463a-8834-18ea60bcb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import get_classification_metrics\n",
    "\n",
    "class PTBXLWaveFormClassifier(LightningModule):\n",
    "    def __init__(self, classifier: nn.Module, learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.classifier = classifier\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_hyperparameters('learning_rate')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def _common_step(self, batch, batch_ids, stage, log=True):\n",
    "        x, labels = batch\n",
    "        probs = self(x)\n",
    "        log_probs = torch.log(probs)\n",
    "        preds = log_probs.argmax(axis=1)\n",
    "        if log:\n",
    "            y_pred_proba = probs.detach().numpy()\n",
    "            metrics = get_classification_metrics(y_pred_proba, labels, auc=True)\n",
    "            for metric, val in metrics.items():\n",
    "                self.log(f\"{stage}/{metric}\", val, on_step=False, on_epoch=True)\n",
    "        return labels, probs, log_probs, preds\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels, probs, log_probs, preds = self._common_step(batch, batch_idx, 'train', log=True)\n",
    "        loss = F.nll_loss(log_probs, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels, probs, log_probs, preds = self._common_step(batch, batch_idx, 'val', log=True)\n",
    "        loss = F.nll_loss(log_probs, labels)\n",
    "        return log_probs\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        _, _, _, preds = self._common_step(batch, batch_idx, 'predict', log=False)\n",
    "        return preds\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, _, _, preds = self._common_step(batch, batch_idx, 'test', log=True)\n",
    "        return preds\n",
    "    \n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        pass\n",
    "        # dummy_input = torch.zeros((1, self.hparams[\"in_dims\"]), device=self.device)\n",
    "        # model_filename = \"model_final.onnx\"\n",
    "        # self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "        # wandb.save(model_filename)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7942e9c-25f5-494e-be7b-f994b1aff49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shate/.local/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/shate/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name       | Type           | Params\n",
      "----------------------------------------------\n",
      "0 | classifier | LSTMClassifier | 362 K \n",
      "----------------------------------------------\n",
      "362 K     Trainable params\n",
      "0         Non-trainable params\n",
      "362 K     Total params\n",
      "1.448     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c6ecdf199f4408ba68e6030e665dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shate/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "classifier = LSTMClassifier(\n",
    "    in_dim = 600, # 12 ECG channels, 50 features per beat\n",
    "    hidden_dim = 100, \n",
    "    num_layers = 2, \n",
    "    bidirectional = False, \n",
    "    n_classes = 5\n",
    ")\n",
    "model = PTBXLWaveFormClassifier(classifier, learning_rate=1e-3)\n",
    "trainer = Trainer()\n",
    "trainer.fit(model, ptbxl_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d35c669-2f23-4a98-b7f0-6bcd93da50c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000be7072b8f4f4b899855d1aa726ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6537530266343826     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/auc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8033713485644808     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/fscore        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45465998624474696    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6537530266343826    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/auc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8033713485644808    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/fscore       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45465998624474696   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/fscore': 0.45465998624474696,\n",
       "  'test/acc': 0.6537530266343826,\n",
       "  'test/auc': 0.8033713485644808}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, ptbxl_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838f725-7ff3-4046-ba50-4d38bdb75301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
